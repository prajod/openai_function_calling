{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e67f200",
   "metadata": {},
   "source": [
    "# RAG using Function calling for tabular data ingestion\n",
    "\n",
    "This notebook covers how to use the Chat Completions API in combination with external functions to extend the capabilities of GPT models.\n",
    "\n",
    "`tools` is an optional parameter in the Chat Completion API which can be used to provide function specifications. The purpose of this is to enable models to generate function arguments which adhere to the provided specifications. Note that the API will not actually execute any function calls. It is up to developers to execute function calls using model outputs.\n",
    "\n",
    "Within the `tools` parameter, if the `functions` parameter is provided then by default the model will decide when it is appropriate to use one of the functions. The API can be forced to use a specific function by setting the `tool_choice` parameter to `{\"name\": \"<insert-function-name>\"}`. The API can also be forced to not use any function by setting the `tool_choice` parameter to `\"none\"`. If a function is used, the output will contain `\"finish_reason\": \"function_call\"` in the response, as well as a `tool_choice` object that has the name of the function and the generated function arguments.\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook contains the following 2 sections:\n",
    "\n",
    "- **How to generate function arguments:** Specify a set of functions and use the API to generate function arguments.\n",
    "- **How to call functions with model generated arguments:** Close the loop by actually executing functions with model generated arguments."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64c85e26",
   "metadata": {},
   "source": [
    "## Function calling using the tools feature of the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "dab872c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import requests\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69ee6a93",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Define a utility function for making calls to the Chat Completions API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "745ceec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function that is used to call the Open AI Chat completion API\n",
    "def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if tools is not None:\n",
    "        json_data.update({\"tools\": tools})\n",
    "    if tool_choice is not None:\n",
    "        json_data.update({\"tool_choice\": tool_choice})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29d4e02b",
   "metadata": {},
   "source": [
    "### Defining a function spec\n",
    "\n",
    "Let's create a function specifications to get sales information for chocolates. We'll pass this function specification to the Chat Completions API in order to generate function arguments that adhere to the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d2e25069",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tools = [ \n",
    "          {\n",
    "            \"type\": \"function\",\n",
    "           \"function\":\n",
    "            { \n",
    "              \"name\": \"get_sales_info\", \n",
    "              \"description\": \"Get the sales information for chocolates\",\n",
    "              \"parameters\": \n",
    "              {\n",
    "                  \"type\": \"object\",\n",
    "                  \"properties\": \n",
    "                  {\n",
    "                    \n",
    "                  }\n",
    "                \n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "planogram_prompt = '''You are an expert planogram designer. I need your help in designing a planogram for a shelf, in a Retail Store in Bangalore.  The shelf is in the chocolates aisle. The shelf has 5 columns and 4 rows. Each cell in the shelf can hold one chocolate box. So the shelf can hold a total of 5 x 4 = 20 chocolate boxes. I want to prioritize in the following order(highest priority is listed first and lowest is listed last):market share, then margin share, then new product, then core product. It is very important that the returned planogram should be in the format given below. Do not leave any cell empty. Can you help me with the planogram design ?\n",
    "\n",
    "[[\"AAA\", \"AAA\", \"AAA\", \"AAA\", \"AAA\"],\n",
    " [\"AAA\", \"AAA\", \"AAA\", \"AAA\", \"AAA\"],\n",
    " [\"AAA\", \"AAA\", \"AAA\", \"AAA\", \"AAA\"],\n",
    " [\"AAA\", \"AAA\", \"AAA\", \"AAA\", \"AAA\"]]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sales_info():\n",
    "    with open('sales_info.json') as fp:\n",
    "        sales_info = json.load(fp)\n",
    "    return sales_info\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b758a0a",
   "metadata": {},
   "source": [
    "#### Forcing the use of specific functions or no function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "412f79ba",
   "metadata": {},
   "source": [
    "We can force the model to use a specific function, if the function named \"get_sales_info\", by using the function argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "559371b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': None,\n",
       " 'tool_calls': [{'id': 'call_RSjhpuBhzb5w6VgjlfN1l4Tf',\n",
       "   'type': 'function',\n",
       "   'function': {'name': 'get_sales_info', 'arguments': '{}'}}]}"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in this cell we force the model to use the function named \"get_sales_info\"\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": planogram_prompt})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools, tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_sales_info\"}}\n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "65585e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will check the intermediate json response from the model to see if is has asked us to \"call\" a function. \n",
    "# If there is a function call request with the correct function name, that function will be invoked\n",
    "\n",
    "def execute_function_call(message):\n",
    "    if message[\"tool_calls\"][0][\"function\"][\"name\"] == \"get_sales_info\":\n",
    "        results = get_sales_info()\n",
    "    else:\n",
    "        results = f\"Error: function {message['tool_calls'][0]['function']['name']} does not exist\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "38c55083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant Message = {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_RSjhpuBhzb5w6VgjlfN1l4Tf', 'type': 'function', 'function': {'name': 'get_sales_info', 'arguments': '{}'}}]}\n",
      "Messages = [{'role': 'system', 'content': \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"}, {'role': 'user', 'content': 'You are an expert planogram designer. I need your help in designing a planogram for a shelf, in a Retail Store in Bangalore.  The shelf is in the chocolates aisle. The shelf has 5 columns and 4 rows. Each cell in the shelf can hold one chocolate box. So the shelf can hold a total of 5 x 4 = 20 chocolate boxes. I want to prioritize in the following order(highest priority is listed first and lowest is listed last):market share, then margin share, then new product, then core product. It is very important that the returned planogram should be in the format given below. Do not leave any cell empty. Can you help me with the planogram design ?\\n\\n[[\"AAA\", \"AAA\", \"AAA\", \"AAA\", \"AAA\"],\\n [\"AAA\", \"AAA\", \"AAA\", \"AAA\", \"AAA\"],\\n [\"AAA\", \"AAA\", \"AAA\", \"AAA\", \"AAA\"],\\n [\"AAA\", \"AAA\", \"AAA\", \"AAA\", \"AAA\"]]'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_RSjhpuBhzb5w6VgjlfN1l4Tf', 'type': 'function', 'function': {'name': 'get_sales_info', 'arguments': '{}'}}]}, {'role': 'tool', 'tool_call_id': 'call_RSjhpuBhzb5w6VgjlfN1l4Tf', 'name': 'get_sales_info', 'content': \"{'sales_info': {'market_share_percentage': {'Munch': 40, 'Milky bar': 30, 'KitKat': 20, 'BarOne': 5}, 'margin_share_percentage': {'Munch': 6, 'Milky bar': 15, 'KitKat': 10, 'BarOne': 12}, 'core_product': {'Munch': 'No', 'Milky bar': 'No', 'KitKat': 'Yes', 'BarOne': 'No'}, 'new_product': {'Munch': 'No', 'Milky bar': 'No', 'KitKat': 'No', 'BarOne': 'Yes'}}}\"}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-8LdFlV0SUzhNamKfd25eBRooy8IP1',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1700166469,\n",
       " 'model': 'gpt-3.5-turbo-0613',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'Based on the sales information provided, here is the planogram for the shelf in the chocolates aisle:\\n\\n```\\n[[\"Munch\", \"Munch\", \"Milky bar\", \"KitKat\", \"AAA\"],\\n [\"Milky bar\", \"KitKat\", \"AAA\", \"AAA\", \"AAA\"],\\n [\"AAA\", \"AAA\", \"AAA\", \"AAA\", \"AAA\"],\\n [\"AAA\", \"AAA\", \"AAA\", \"BarOne\", \"BarOne\"]]\\n```\\n\\nExplanation:\\n- The highest priority is given to market share. Therefore, the chocolates with the highest market share percentages are placed first.\\n- The second priority is margin share, followed by new product and core product.\\n- AAA is used to fill the remaining cells on the shelf to ensure that all cells are filled.\\n\\nPlease note that the planogram is based on the available sales information and the specified prioritization order.'},\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 426,\n",
       "  'completion_tokens': 178,\n",
       "  'total_tokens': 604}}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "# chat_response.json()[\"choices\"][0][\"message\"]\n",
    "messages.append(assistant_message)\n",
    "if assistant_message.get(\"tool_calls\"):\n",
    "    results = execute_function_call(assistant_message)\n",
    "    messages.append({\"role\": \"tool\", \"tool_call_id\": assistant_message[\"tool_calls\"][0]['id'], \"name\": assistant_message[\"tool_calls\"][0][\"function\"][\"name\"], \"content\": f\"{results}\"})\n",
    "\n",
    "print(f\"Assistant Message = {assistant_message}\")\n",
    "print(f\"Messages = {messages}\")\n",
    "chat_response_2 = chat_completion_request(messages, tools)\n",
    "chat_response_2.json()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
